{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abfd1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from datetime import timedelta\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score,f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sktime.transformations.panel.rocket import Rocket\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e94412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('PostgreSQL 15.2, compiled by Visual C++ build 1914, 64-bit',)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    database=\"mimic\",\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT version();\")\n",
    "print(cur.fetchone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c6df0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navim\\AppData\\Local\\Temp\\ipykernel_18480\\3511136484.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  icustay_details = pd.read_sql_query(\"SELECT * FROM mimiciii.flicu_icustay_detail;\", conn)\n",
      "C:\\Users\\navim\\AppData\\Local\\Temp\\ipykernel_18480\\3511136484.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pivoted_vital = pd.read_sql_query(\"SELECT * FROM mimiciii.pivoted_vital;\", conn)\n",
      "C:\\Users\\navim\\AppData\\Local\\Temp\\ipykernel_18480\\3511136484.py:10: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pivoted_lab = pd.read_sql_query(\"SELECT * FROM mimiciii.ckd_pivoted_lab;\", conn)\n"
     ]
    }
   ],
   "source": [
    "# Connect to db\n",
    "conn = psycopg2.connect(host='localhost', dbname='mimic', user='postgres', password='postgres', options='-c search_path=mimiciii')\n",
    "cur = conn.cursor() \n",
    "\n",
    "# Read in table with patients & admissions (inner join on subject_id) and icu_stays (inner joinon subject_id and hadm_id)\n",
    "icustay_details = pd.read_sql_query(\"SELECT * FROM mimiciii.flicu_icustay_detail;\", conn)\n",
    "\n",
    "# Read in vital and lab signs\n",
    "pivoted_vital = pd.read_sql_query(\"SELECT * FROM mimiciii.pivoted_vital;\", conn)\n",
    "pivoted_lab = pd.read_sql_query(\"SELECT * FROM mimiciii.ckd_pivoted_lab;\", conn)\n",
    "\n",
    "# Close the cursor and connection to so the server can allocate bandwidth to other requests\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "707d14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_LENGTH = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7870a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= icustay_details.copy()\n",
    "data = data[data.los_icu >= WINDOW_LENGTH/24.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "981783e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_icustay_ids = pd.DataFrame(data['icustay_id'].unique(), columns=['icustay_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bde3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop measurements with no belonging icustay_id\n",
    "pivoted_vital = pivoted_vital.dropna(subset=['icustay_id'])\n",
    "pivoted_lab = pivoted_lab.dropna(subset=['icustay_id'])\n",
    "\n",
    "# Cast icustay_id types to int\n",
    "pivoted_vital['icustay_id'] = pivoted_vital['icustay_id'].astype(int)\n",
    "pivoted_lab['icustay_id'] = pivoted_lab['icustay_id'].astype(int)\n",
    "\n",
    "# Keep only values of patients in previously filtered icustay_ids in labs and vitals\n",
    "pivoted_vital = pivoted_vital.merge(filtered_icustay_ids, on='icustay_id', how='right').drop_duplicates()\n",
    "pivoted_lab = pivoted_lab.merge(filtered_icustay_ids, on='icustay_id', how='right').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee01fc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min of each lab and vitals\n",
    "icustay_ids_charttime_min_lab = pivoted_lab[[\"icustay_id\", \"charttime\"]][pivoted_lab.groupby(\"icustay_id\")[\"charttime\"].rank(ascending=1,method='dense') == 1]\n",
    "icustay_ids_charttime_min_vital = pivoted_vital[[\"icustay_id\", \"charttime\"]][pivoted_vital.groupby(\"icustay_id\")[\"charttime\"].rank(ascending=1,method='dense') == 1]\n",
    "# Min of both combined\n",
    "icustay_ids_charttime_min_vital_lab = pd.concat([icustay_ids_charttime_min_lab, icustay_ids_charttime_min_vital], ignore_index=True)\n",
    "icustay_ids_charttime_min_vital_lab = icustay_ids_charttime_min_vital_lab[[\"icustay_id\", \"charttime\"]][icustay_ids_charttime_min_vital_lab.groupby(\"icustay_id\")[\"charttime\"].rank(ascending=1,method='dense') == 1]\n",
    "\n",
    "# Max of each lab and vitals\n",
    "icustay_ids_charttime_max_lab = pivoted_lab[[\"icustay_id\", \"charttime\"]][pivoted_lab.groupby(\"icustay_id\")[\"charttime\"].rank(ascending=0,method='dense') == 1]\n",
    "icustay_ids_charttime_max_vital = pivoted_vital[[\"icustay_id\", \"charttime\"]][pivoted_vital.groupby(\"icustay_id\")[\"charttime\"].rank(ascending=0,method='dense') == 1]\n",
    "# Max of both combined\n",
    "icustay_ids_charttime_max_vital_lab = pd.concat([icustay_ids_charttime_max_lab, icustay_ids_charttime_max_vital], ignore_index=True)\n",
    "icustay_ids_charttime_max_vital_lab = icustay_ids_charttime_max_vital_lab[[\"icustay_id\", \"charttime\"]][icustay_ids_charttime_max_vital_lab.groupby(\"icustay_id\")[\"charttime\"].rank(ascending=0,method='dense') == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93dd92b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique icu stays in icustay_ids_vital_lab_charttime_min_max_filtered after filtering 8409\n",
      "Unique icu stays in icustay_ids_time_filtered:  8409\n"
     ]
    }
   ],
   "source": [
    "# Find for which icustay_ids there exist at least WINDOW_LENGTH of data\n",
    "icustay_ids_vital_lab_charttime_min_max = pd.concat([icustay_ids_charttime_max_vital_lab, icustay_ids_charttime_min_vital_lab], ignore_index=True)\n",
    "time_window = timedelta(days=4, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=WINDOW_LENGTH, weeks=0)\n",
    "is_time_diff_bigger_window_lab = icustay_ids_vital_lab_charttime_min_max.groupby(['icustay_id'])['charttime'].transform(lambda x: (x.max()-x.min())) >= time_window\n",
    "\n",
    "icustay_ids_vital_lab_charttime_min_max_filtered = icustay_ids_vital_lab_charttime_min_max[is_time_diff_bigger_window_lab]\n",
    "print(\"Unique icu stays in icustay_ids_vital_lab_charttime_min_max_filtered after filtering\", icustay_ids_vital_lab_charttime_min_max_filtered['icustay_id'].nunique())\n",
    "\n",
    "# Keep only icustay ids for which at least WINDOW_LENGTH of data exists\n",
    "icustay_ids_time_filtered = pd.DataFrame(icustay_ids_vital_lab_charttime_min_max_filtered['icustay_id'].unique(), columns=['icustay_id'])\n",
    "print(\"Unique icu stays in icustay_ids_time_filtered: \", icustay_ids_time_filtered['icustay_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d0b2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_icustay_ids = filtered_icustay_ids.merge(icustay_ids_time_filtered, on='icustay_id', how='inner').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c348e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ICU stays demographics:  8409\n",
      "Number of ICU stays vitals:  8409\n",
      "Number of ICU stays labs:  8409\n"
     ]
    }
   ],
   "source": [
    "demographics_filtered = data.merge(filtered_icustay_ids, on='icustay_id', how='right').drop_duplicates()\n",
    "print(\"Number of ICU stays demographics: \", demographics_filtered['icustay_id'].nunique())\n",
    "\n",
    "vital_filtered = pivoted_vital.merge(filtered_icustay_ids, on='icustay_id', how='right').drop_duplicates()\n",
    "print(\"Number of ICU stays vitals: \", vital_filtered['icustay_id'].nunique())\n",
    "\n",
    "lab_filtered = pivoted_lab.merge(filtered_icustay_ids, on='icustay_id', how='right').drop_duplicates()\n",
    "print(\"Number of ICU stays labs: \", lab_filtered['icustay_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ee42955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ICU stays in lab_filtered:  8409\n",
      "Number of ICU stays in lab_filtered:  8409\n"
     ]
    }
   ],
   "source": [
    "vital_filtered = vital_filtered.merge(lab_filtered[['icustay_id', 'charttime']], on=['icustay_id', 'charttime'], how='outer').drop_duplicates()\n",
    "print(\"Number of ICU stays in lab_filtered: \", vital_filtered['icustay_id'].nunique())\n",
    "lab_filtered = lab_filtered.merge(vital_filtered[['icustay_id', 'charttime']], on=['icustay_id', 'charttime'], how='outer').drop_duplicates()\n",
    "print(\"Number of ICU stays in lab_filtered: \", lab_filtered['icustay_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44d46d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navim\\AppData\\Local\\Temp\\ipykernel_18480\\2079071312.py:12: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  vital_resampled = vital_resampled.set_index(['icustay_id', 'charttime']).groupby('icustay_id')[vital_col].transform(lambda x: x.ffill().bfill()).fillna(value=vital_resampled[['icustay_id', 'charttime', 'heartrate', 'sysbp', 'diasbp', 'meanbp','resprate', 'tempc', 'spo2', 'glucose', 'rbc', 'specificgravity','pedaledema', 'appetite_median']].median()).reset_index()\n"
     ]
    }
   ],
   "source": [
    "vital_resampled = vital_filtered.copy()\n",
    "\n",
    "# Resample from the end of the time series (how=\"last\")\n",
    "vital_resampled = vital_resampled.assign(charttime=vital_resampled.charttime.dt.round('H'))\n",
    "\n",
    "# Resample from the beginning of the time series\n",
    "vital_resampled = vital_resampled.set_index('charttime').groupby('icustay_id').resample('1H', origin=\"start\").median().drop(['icustay_id'], axis = 1).reset_index()\n",
    "\n",
    "# Forward and backwards fill (use lambda function instead of directly applying it to groupby otherwise results from one group are carreid forward to another group...BAD)\n",
    "# Fill NaNs (-1)\n",
    "vital_col = vital_resampled.columns.drop(['icustay_id', 'charttime'])\n",
    "vital_resampled = vital_resampled.set_index(['icustay_id', 'charttime']).groupby('icustay_id')[vital_col].transform(lambda x: x.ffill().bfill()).fillna(value=vital_resampled[['icustay_id', 'charttime', 'heartrate', 'sysbp', 'diasbp', 'meanbp','resprate', 'tempc', 'spo2', 'glucose', 'rbc', 'specificgravity','pedaledema', 'appetite_median']].median()).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbc3a7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navim\\AppData\\Local\\Temp\\ipykernel_18480\\3063204683.py:11: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  lab_resampled = lab_resampled.set_index(['icustay_id', 'charttime']).groupby('icustay_id')[lab_col].transform(lambda x: x.ffill().bfill()).fillna(value=lab_resampled[['icustay_id', 'subject_id', 'charttime', 'aniongap', 'albumin', 'bands','bicarbonate', 'bilirubin', 'creatinine', 'chloride', 'glucose','hematocrit', 'hemoglobin', 'lactate', 'platelet', 'potassium', 'ptt','inr', 'pt', 'sodium', 'bun', 'wbc', 'bacteria']].median()).reset_index()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730\n"
     ]
    }
   ],
   "source": [
    "lab_resampled = lab_filtered.copy()\n",
    "# Cut out minutes and hours, so that the resampling of the 8h takes the same time span as the 1h samples (for vitals)\n",
    "lab_resampled = lab_resampled.assign(charttime=lab_resampled.charttime.dt.round('H'))\n",
    "# Resample from the end of the time series \n",
    "#lab_resampled = lab_resampled.set_index('charttime').groupby('icustay_id').resample('8h', origin=\"end\").median().drop(['icustay_id'], axis = 1).reset_index()\n",
    "lab_resampled = lab_resampled.set_index('charttime').groupby('icustay_id').resample('8h', origin=\"start\").median().drop(['icustay_id'], axis = 1).reset_index()\n",
    "\n",
    "# Forward and backwards fill (use transform instead of direct groupby otherwise results from one group are carreid forward to another group...BAD)\n",
    "# Fill NaNs (-1 or 0 or mean!?)\n",
    "lab_col = lab_resampled.columns.drop(['icustay_id', 'charttime'])\n",
    "lab_resampled = lab_resampled.set_index(['icustay_id', 'charttime']).groupby('icustay_id')[lab_col].transform(lambda x: x.ffill().bfill()).fillna(value=lab_resampled[['icustay_id', 'subject_id', 'charttime', 'aniongap', 'albumin', 'bands','bicarbonate', 'bilirubin', 'creatinine', 'chloride', 'glucose','hematocrit', 'hemoglobin', 'lactate', 'platelet', 'potassium', 'ptt','inr', 'pt', 'sodium', 'bun', 'wbc', 'bacteria']].median()).reset_index()\n",
    "\n",
    "print(lab_resampled.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e552964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>intime</th>\n",
       "      <th>predtime</th>\n",
       "      <th>delta_t_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>334</td>\n",
       "      <td>214236</td>\n",
       "      <td>2136-01-16 10:56:48</td>\n",
       "      <td>2136-01-20 10:56:48</td>\n",
       "      <td>10 days 07:21:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005</td>\n",
       "      <td>285731</td>\n",
       "      <td>2163-06-23 11:28:06</td>\n",
       "      <td>2163-06-27 11:28:06</td>\n",
       "      <td>5 days 08:45:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12174</td>\n",
       "      <td>284866</td>\n",
       "      <td>2118-10-30 16:48:57</td>\n",
       "      <td>2118-11-03 16:48:57</td>\n",
       "      <td>13 days 00:44:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13535</td>\n",
       "      <td>205010</td>\n",
       "      <td>2196-10-10 22:03:14</td>\n",
       "      <td>2196-10-14 22:03:14</td>\n",
       "      <td>88 days 19:52:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21824</td>\n",
       "      <td>241223</td>\n",
       "      <td>2107-07-07 20:58:00</td>\n",
       "      <td>2107-07-11 20:58:00</td>\n",
       "      <td>31 days 15:33:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  icustay_id              intime            predtime  \\\n",
       "0         334      214236 2136-01-16 10:56:48 2136-01-20 10:56:48   \n",
       "1        2005      285731 2163-06-23 11:28:06 2163-06-27 11:28:06   \n",
       "2       12174      284866 2118-10-30 16:48:57 2118-11-03 16:48:57   \n",
       "3       13535      205010 2196-10-10 22:03:14 2196-10-14 22:03:14   \n",
       "4       21824      241223 2107-07-07 20:58:00 2107-07-11 20:58:00   \n",
       "\n",
       "      delta_t_pred  \n",
       "0 10 days 07:21:18  \n",
       "1  5 days 08:45:56  \n",
       "2 13 days 00:44:12  \n",
       "3 88 days 19:52:36  \n",
       "4 31 days 15:33:00  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_t_data = timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=WINDOW_LENGTH, weeks=0)\n",
    "demographics_windowed = demographics_filtered.copy()\n",
    "demographics_windowed['predtime'] = demographics_windowed.intime + delta_t_data\n",
    "demographics_windowed['delta_t_pred'] = demographics_windowed.outtime - demographics_windowed.predtime\n",
    "\n",
    "demographics_windowed[['subject_id', 'icustay_id', 'intime', 'predtime', 'delta_t_pred']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709771ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ICU stays:  8409\n",
      "Number of ICU stays in vitals_cut:  8409\n",
      "Number of ICU stays in labs_cut:  8409\n"
     ]
    }
   ],
   "source": [
    "cut_icustay_ids = pd.DataFrame(demographics_windowed['icustay_id'].unique(), columns=['icustay_id'])\n",
    "print(\"Number of ICU stays: \", cut_icustay_ids['icustay_id'].count())\n",
    "\n",
    "vitals_cut = vital_resampled.merge(cut_icustay_ids, on='icustay_id', how='right')\n",
    "print(\"Number of ICU stays in vitals_cut: \", vitals_cut['icustay_id'].nunique())\n",
    "\n",
    "labs_cut = lab_resampled.merge(cut_icustay_ids, on='icustay_id', how='right')\n",
    "print(\"Number of ICU stays in labs_cut: \", labs_cut['icustay_id'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9069a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ICU stays in vitals_windowed:  8405\n",
      "Number of ICU stays in labs_windowed:  8405\n"
     ]
    }
   ],
   "source": [
    "vitals_windowed = vital_resampled.merge(demographics_windowed[['icustay_id', 'predtime', 'delta_t_pred']], on='icustay_id', how='right')\n",
    "vitals_windowed = vitals_windowed[vitals_windowed.charttime < vitals_windowed.predtime]\n",
    "print(\"Number of ICU stays in vitals_windowed: \", vitals_windowed['icustay_id'].nunique())\n",
    "\n",
    "labs_windowed = lab_resampled.merge(demographics_windowed[['icustay_id', 'predtime', 'delta_t_pred']], on='icustay_id', how='right')\n",
    "labs_windowed = labs_windowed[labs_windowed.charttime < labs_windowed.predtime]\n",
    "print(\"Number of ICU stays in labs_windowed: \", labs_windowed['icustay_id'].nunique())\n",
    "\n",
    "windowed_icustay_ids = pd.DataFrame(pd.concat([vitals_windowed['icustay_id'], labs_windowed['icustay_id']]).unique(), columns=['icustay_id'])\n",
    "demographics_windowed = demographics_windowed.merge(windowed_icustay_ids, on='icustay_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc63b7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_windowed['ckd'] = vitals_windowed['icustay_id'].map(demographics_windowed.set_index('icustay_id')['ckd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a27abb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_windowed =vitals_windowed.set_index(['icustay_id', 'charttime']).groupby('icustay_id')[vital_col].transform(lambda x: x.ffill().bfill()).fillna(-1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37e572dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_windowed['ckd'] = labs_windowed['icustay_id'].map(demographics_windowed.set_index('icustay_id')['ckd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca29bece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ICU stays demographics:  8405\n",
      "Number of CKD demographics:\n",
      "0    7868\n",
      "1     537\n",
      "Name: ckd, dtype: int64\n",
      "Number of ICU stays vitals:  8405\n",
      "Number of CKD vitals:\n",
      "0    7868\n",
      "1     537\n",
      "Name: ckd, dtype: int64\n",
      "Number of ICU stays labs:  8405\n",
      "Number of CKD labs:\n",
      "0    7868\n",
      "1     537\n",
      "Name: ckd, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of ICU stays demographics: \", demographics_windowed['icustay_id'].nunique())\n",
    "print(\"Number of CKD demographics:\")\n",
    "dd = demographics_windowed[['icustay_id','ckd']].drop_duplicates(subset=['icustay_id'])\n",
    "print(dd['ckd'].value_counts())\n",
    "\n",
    "print(\"Number of ICU stays vitals: \", vitals_windowed['icustay_id'].nunique())\n",
    "print(\"Number of CKD vitals:\")\n",
    "dd = vitals_windowed[['icustay_id','ckd']].drop_duplicates(subset=['icustay_id'])\n",
    "print(dd['ckd'].value_counts())\n",
    "\n",
    "print(\"Number of ICU stays labs: \", labs_windowed['icustay_id'].nunique())\n",
    "print(\"Number of CKD labs:\")\n",
    "dd = labs_windowed[['icustay_id','ckd']].drop_duplicates(subset=['icustay_id'])\n",
    "print(dd['ckd'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "072281db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_dataframe(df, groupby_key, columns_to_aggregate):\n",
    "    df = df.replace(-1, np.nan)\n",
    "    result = df.groupby(groupby_key)[columns_to_aggregate].mean().reset_index()    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e76872f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vitals unique icustay id:  8405 \n",
      "Labs unique icustay id:  8405 \n",
      "Demographics unique icustay id:  8405\n"
     ]
    }
   ],
   "source": [
    "columns_to_merge = ['icustay_id', 'ckd','ethnicity_grouped']\n",
    "df_cols_vitals = ['heartrate', 'sysbp','diasbp','meanbp','resprate','tempc','spo2','specificgravity','pedaledema','appetite_median']\n",
    "df_agg_vitals = aggregate_dataframe(vitals_windowed, 'icustay_id', df_cols_vitals)\n",
    "df_agg_vitals = df_agg_vitals.merge(demographics_windowed[columns_to_merge], on='icustay_id', how='inner')\n",
    "df_agg_vitals['ckd_ethnicity'] = df_agg_vitals['ckd'].astype(str).str.cat(df_agg_vitals['ethnicity_grouped'].astype(str))\n",
    "\n",
    "df_cols_labs = ['albumin','bacteria','glucose','bun','creatinine','sodium','potassium','hemoglobin','wbc','hematocrit','platelet','ptt']\n",
    "df_agg_labs = aggregate_dataframe(labs_windowed, 'icustay_id', df_cols_labs)\n",
    "df_agg_labs = df_agg_labs.merge(demographics_windowed[columns_to_merge], on='icustay_id', how='inner')\n",
    "df_agg_labs['ckd_ethnicity'] = df_agg_labs['ckd'].astype(str).str.cat(df_agg_labs['ethnicity_grouped'].astype(str))\n",
    "\n",
    "print(\"Vitals unique icustay id: \",len(df_agg_vitals['icustay_id'].unique()),\"\\nLabs unique icustay id: \",len(df_agg_labs['icustay_id'].unique()),\"\\nDemographics unique icustay id: \",len(demographics_windowed['icustay_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea257a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_vitals_new=df_agg_vitals.drop(['ckd','ethnicity_grouped','ckd_ethnicity','pedaledema'],axis=1)\n",
    "df_agg_labs_new=df_agg_labs.drop(['ckd','ethnicity_grouped','ckd_ethnicity'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb367b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_table_org = df_agg_labs_new.merge(df_agg_vitals_new, on='icustay_id', how='inner').merge(demographics_windowed, on='icustay_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cffcbde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_table =merged_table_org.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8209d5",
   "metadata": {},
   "source": [
    "Table names : \n",
    "- demographics_windowed\n",
    "- labs_windowed\n",
    "- vitals_windowed\n",
    "- df_agg_vitals\n",
    "- df_agg_labs\n",
    "- merged_table_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d28648f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3038\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference between max and min charttime for labs_windowed\n",
    "labs_diff = labs_windowed.groupby('icustay_id')['charttime'].apply(lambda x: x.max() - x.min())\n",
    "\n",
    "# Calculate the difference between max and min charttime for vitals_windowed\n",
    "vitals_diff = vitals_windowed.groupby('icustay_id')['charttime'].apply(lambda x: x.max() - x.min())\n",
    "\n",
    "# Filter the icustay_id where the difference is grater than or equal to Window_length in both labs and vitals\n",
    "filtered_icustay_ids = labs_diff[(labs_diff == pd.Timedelta(hours=WINDOW_LENGTH)) & (vitals_diff == pd.Timedelta(hours=WINDOW_LENGTH))].index.tolist()\n",
    "\n",
    "# Print the length of icustay_id\n",
    "print(len(filtered_icustay_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8568d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_table_filtered= merged_table[merged_table['icustay_id'].isin(filtered_icustay_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76cf42fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['icustay_id', 'albumin', 'bacteria', 'glucose', 'bun', 'creatinine',\n",
       "       'sodium', 'potassium', 'hemoglobin', 'wbc', 'hematocrit', 'platelet',\n",
       "       'ptt', 'heartrate', 'sysbp', 'diasbp', 'meanbp', 'resprate', 'tempc',\n",
       "       'spo2', 'specificgravity', 'appetite_median', 'subject_id', 'hadm_id',\n",
       "       'gender', 'dod', 'admittime', 'dischtime', 'los_hospital',\n",
       "       'admission_age', 'ethnicity', 'ethnicity_grouped',\n",
       "       'hospital_expire_flag', 'hospstay_seq', 'first_hosp_stay', 'intime',\n",
       "       'outtime', 'los_icu', 'icustay_seq', 'first_icu_stay_current_hosp',\n",
       "       'first_icu_stay_patient', 'first_careunit', 'deathtime_icu',\n",
       "       'label_death_icu', 'label_cor_art', 'diabetes_mellitus', 'ckd',\n",
       "       'anemia_flag', 'predtime', 'delta_t_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_table_filtered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26bd8805",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_table_filtered=merged_table_filtered.drop(['subject_id','hadm_id','dod','admittime', 'dischtime','los_hospital','ethnicity','hospital_expire_flag','hospstay_seq', 'first_hosp_stay', 'intime','outtime', 'los_icu', 'icustay_seq', 'first_icu_stay_current_hosp','first_icu_stay_patient', 'first_careunit', 'deathtime_icu','label_death_icu', 'predtime', 'delta_t_pred'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce23ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_ranges = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 400]\n",
    "age_labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90+']\n",
    "merged_table_filtered['age_group'] = pd.cut(merged_table_filtered['admission_age'], bins=age_ranges, labels=age_labels, right=False)\n",
    "merged_table_filtered=merged_table_filtered.drop('admission_age',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e20f4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationCV(classifier,X, y):    \n",
    "    cv_scores_pr = cross_val_score(classifier, X, y, cv=5, scoring='precision')    \n",
    "    cv_scores_rc = cross_val_score(classifier, X, y, cv=5, scoring='recall')    \n",
    "    cv_scores_f1 = cross_val_score(classifier,X, y, cv=5, scoring='f1')\n",
    "    cv_scores_ac = cross_val_score(classifier, X, y, cv=5, scoring='accuracy') \n",
    "    \n",
    "    print(\"Cross-validation scores Precision    :\", cv_scores_pr)    \n",
    "    print(\"Cross-validation scores Recall       :\", cv_scores_rc)\n",
    "    print(\"Cross-validation scores F1           :\", cv_scores_f1)\n",
    "    print(\"Cross-validation scores Accuracy     :\", cv_scores_ac)\n",
    "    \n",
    "    print(\"Mean cross-validation score Precision:\", np.mean(cv_scores_pr))\n",
    "    print(\"Mean cross-validation score Recall   :\", np.mean(cv_scores_rc))\n",
    "    print(\"Mean cross-validation score F1       :\", np.mean(cv_scores_f1))\n",
    "    print(\"Mean cross-validation score Accuracy :\", np.mean(cv_scores_ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8baf5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluationTest(classifier,X, y):  \n",
    "    y_pred = classifier.predict(X)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    #print(\"Precision:\", precision)\n",
    "    #print(\"Recall:\", recall)\n",
    "    #print(\"F1 Score:\", f1)\n",
    "    #print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    print(classification_report(y, y_pred))\n",
    "    \n",
    "    return pd.DataFrame(y_pred)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d228bbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricsReport(y,y_pred):\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    print(classification_report(y, y_pred))\n",
    "    \n",
    "    return precision, recall , f1, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ea5d8",
   "metadata": {},
   "source": [
    "#### Data & Class separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6cf80dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = merged_table_filtered.drop(['ckd','icustay_id'],axis=1)\n",
    "#y = merged_table_filtered['ckd']\n",
    "#X_onehot = pd.get_dummies(X)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_onehot, y, test_size=0.20, stratify=y, random_state=42)\n",
    "\n",
    "#param_grid_rcv = {\n",
    "#    'n_estimators': randint(50, 500),\n",
    "#    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "#    'max_depth' : randint(1, 10),\n",
    "#    'criterion' :['gini', 'entropy']\n",
    "#}\n",
    "\n",
    "#param_grid = {\n",
    "#    'n_estimators': [100, 200, 300],\n",
    "#    'max_depth': [None, 5, 10],\n",
    "#    'min_samples_split': [2, 5, 10],\n",
    "#    'min_samples_leaf': [1, 2, 4, 6],\n",
    "#    'max_features': ['sqrt', 'log2','auto']\n",
    "#}\n",
    "\n",
    "#runder = RandomUnderSampler(random_state=42)\n",
    "#X_resampled, y_resampled = runder.fit_resample(X_train, y_train)\n",
    "#rf_merged = RandomForestClassifier(random_state=42)\n",
    "\n",
    "#grid_search = RandomizedSearchCV(estimator=rf_merged, param_distributions=param_grid_rcv, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "#grid_search = GridSearchCV(rf_merged, param_grid, cv=5)\n",
    "#grid_search.fit(X_train, y_train)\n",
    "#grid_search.best_params_\n",
    "\n",
    "#rf_merged_2 = RandomForestClassifier(random_state=42,\n",
    "#                                     max_depth = None, \n",
    "#                                     max_features = 'sqrt',\n",
    "#                                     min_samples_leaf = 1,\n",
    "#                                     min_samples_split = 1,\n",
    "#                                     n_estimators= 100)\n",
    "#\n",
    "#rf_merged_2.fit(X_train, y_train)\n",
    "\n",
    "#X_top =X[['creatinine', 'specificgravity', 'heartrate', 'bun', 'spo2', 'tempc', 'platelet', 'diasbp', 'bacteria', 'meanbp']]\n",
    "#X_onehot = pd.get_dummies(X_top)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_onehot, y, test_size=0.20, stratify=y, random_state=42)\n",
    "#\n",
    "#undersampler = RandomUnderSampler()\n",
    "##undersampler = RandomUnderSampler(sampling_strategy={0: 250})\n",
    "#X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "#\n",
    "#rf_ros = RandomForestClassifier(random_state=42,\n",
    "#                                max_depth = None, \n",
    "#                                max_features = 'sqrt',\n",
    "#                                min_samples_leaf = 1,\n",
    "#                                min_samples_split = 1,\n",
    "#                                n_estimators= 100)\n",
    "#\n",
    "#rf_ros.fit(X_resampled, y_resampled)\n",
    "#evaluationCV(rf_ros,X_resampled, y_resampled)\n",
    "#\n",
    "#rf_ros.fit(X_resampled, y_resampled)\n",
    "#y_pred_ros = evaluationTest(rf_ros,X_test, y_test)\n",
    "#y_pred_ros.value_counts()\n",
    "\n",
    "\n",
    "#X_onehot = pd.get_dummies(X)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_onehot, y, test_size=0.20, stratify=y, random_state=42)\n",
    "#\n",
    "#undersampler = RandomUnderSampler()\n",
    "##undersampler = RandomUnderSampler(sampling_strategy={0: 250})\n",
    "#X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "#\n",
    "#rf_ros = RandomForestClassifier(random_state=42,\n",
    "#                                max_depth = None, \n",
    "#                                max_features = 'sqrt',\n",
    "#                                min_samples_leaf = 1,\n",
    "#                                min_samples_split = 1,\n",
    "#                                n_estimators= 100)\n",
    "#\n",
    "#rf_ros.fit(X_resampled, y_resampled)\n",
    "#evaluationCV(rf_ros,X_resampled, y_resampled)\n",
    "#\n",
    "#rf_ros.fit(X_resampled, y_resampled)\n",
    "#y_pred_ros = evaluationTest(rf_ros,X_test, y_test)\n",
    "#y_pred_ros.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b171c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_with_sampling(clf, X,y, resampling = None):\n",
    "        \n",
    "    X = X.values\n",
    "    y = y.values\n",
    "   \n",
    "    label0_prec=[]\n",
    "    label0_rec=[]\n",
    "    label0_f1=[]   \n",
    "    label1_prec=[]\n",
    "    label1_rec=[]\n",
    "    label1_f1=[]   \n",
    "    acc_val=[]\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    for train_index, test_index in kfold.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        if resampling == None:\n",
    "            print(\"CV : No resampling: Train:\", y_train.shape[0] , \"Test:\", y_test.shape[0])\n",
    "        elif (resampling.lower() == 'under'):\n",
    "            sampler = RandomUnderSampler(random_state=42)\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "            print(\"CV: Under sampling: Train:\", y_train.shape[0] , \"Test:\", y_test.shape[0])\n",
    "        elif (resampling.lower() == 'over'):\n",
    "            sampler = SMOTE(random_state=42)\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "            print(\"CV: Over sampling: Train:\", y_train.shape[0] , \"Test:\", y_test.shape[0])\n",
    "        \n",
    "        clf.fit(X_train, y_train)\n",
    "        #y_pred_validation = evaluationTest(clf, X_test, y_test)\n",
    "        y_pred_validation = clf.predict(X_test)\n",
    "        \n",
    "        clf_res=classification_report(y_test,y_pred_validation,output_dict=True)\n",
    "        label0, label1, acc=(clf_res['0'],clf_res['1'],clf_res['accuracy'])\n",
    "        \n",
    "        label0_prec.append(round(label0['precision'], 2))\n",
    "        label0_rec.append(round(label0['recall'], 2))\n",
    "        label0_f1.append(round(label0['f1-score'], 2))        \n",
    "        label1_prec.append(round(label1['precision'], 2))\n",
    "        label1_rec.append(round(label1['recall'], 2))\n",
    "        label1_f1.append(round(label1['f1-score'], 2))        \n",
    "        acc_val.append(round(acc, 2))\n",
    "    \n",
    "    print(\"---------CV : Label 0----------------\")\n",
    "    print(\"CV:Precision: \",label0_prec)   \n",
    "    print(\"CV:Recall   :\",label0_rec)\n",
    "    print(\"CV:F1-score :\",label0_f1)\n",
    "    \n",
    "    print(\"\\nCV:Precision Mean:\",round(statistics.mean(label0_prec), 2))\n",
    "    print(\"CV:Recall Mean:\",round(statistics.mean(label0_rec), 2))\n",
    "    print(\"CV:F1-score Mean:\",round(statistics.mean(label0_f1), 2))                        \n",
    "                         \n",
    "    print(\"---------CV : Label 1----------------\")\n",
    "    print(\"CV:Precision: \",label1_prec)\n",
    "    print(\"CV:Recall   :\",label1_rec)\n",
    "    print(\"CV:F1-score :\",label1_f1)\n",
    "    \n",
    "    print(\"\\nCV:Precision Mean:\",round(statistics.mean(label1_prec), 2))\n",
    "    print(\"CV:Recall Mean:\",round(statistics.mean(label1_rec), 2))\n",
    "    print(\"CV:F1-score Mean:\",round(statistics.mean(label1_f1), 2))\n",
    "    print(\"---------Accuracy CV----------------\")\n",
    "    print(\"CV: Accuracy \",round(statistics.mean(acc_val), 2))\n",
    "    print(\"------------------------------------\")\n",
    "    \n",
    "    return clf, y_pred_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "edcbe79f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_onehot = pd.get_dummies(X_top)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_onehot, y, test_size=0.20, stratify=y, random_state=42)\n",
    "#\n",
    "#undersampler = RandomUnderSampler()\n",
    "#X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "#\n",
    "#brf = BalancedRandomForestClassifier(n_estimators=100)\n",
    "#brf.fit(X_resampled, y_resampled)\n",
    "#\n",
    "#evaluationCV(brf,X_resampled, y_resampled)\n",
    "#\n",
    "#y_pred_brf = evaluationTest(brf,X_test, y_test)\n",
    "#y_pred_brf.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fe940a",
   "metadata": {},
   "source": [
    "# 2. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff00ea",
   "metadata": {},
   "source": [
    "demographics_windowed\n",
    "\n",
    "merged_table\n",
    "\n",
    "--------------------------------\n",
    "static_demo_comorb\n",
    "\n",
    "labs_windowed\n",
    "\n",
    "vitals_windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6571932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_ranges = [0, 9, 19, 29, 39, 49, 59, 69, 79, 89, 400]\n",
    "age_labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90+']\n",
    "demographics_windowed['age_group'] = pd.cut(merged_table['admission_age'], bins=age_ranges, labels=age_labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43d79967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "static_demo_comorb = demographics_windowed[['icustay_id','gender', 'ethnicity_grouped', 'label_cor_art', 'diabetes_mellitus', 'anemia_flag', 'age_group', 'ckd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "caef0d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No icustay_id missing from static_demo_comorb\n",
      "No icustay_id missing from labs_windowed\n",
      "No icustay_id missing from vitals_windowed\n"
     ]
    }
   ],
   "source": [
    "# Get the unique icustay_id values from each DataFrame\n",
    "icustay_id_df1 = set(static_demo_comorb['icustay_id'])\n",
    "icustay_id_df2 = set(labs_windowed['icustay_id'])\n",
    "icustay_id_df3 = set(vitals_windowed['icustay_id'])\n",
    "\n",
    "# Check for missing icustay_id values\n",
    "missing_from_df1 = icustay_id_df2.union(icustay_id_df3) - icustay_id_df1\n",
    "missing_from_df2 = icustay_id_df1.union(icustay_id_df3) - icustay_id_df2\n",
    "missing_from_df3 = icustay_id_df1.union(icustay_id_df2) - icustay_id_df3\n",
    "\n",
    "# Print the missing icustay_id values\n",
    "if missing_from_df1:\n",
    "    print(f\"Icustay_id missing from static_demo_comorb: {missing_from_df1}\")\n",
    "else:\n",
    "    print(\"No icustay_id missing from static_demo_comorb\")\n",
    "\n",
    "if missing_from_df2:\n",
    "    print(f\"Icustay_id missing from labs_windowed: {missing_from_df2}\")\n",
    "else:\n",
    "    print(\"No icustay_id missing from labs_windowed\")\n",
    "\n",
    "if missing_from_df3:\n",
    "    print(f\"Icustay_id missing from vitals_windowed: {missing_from_df3}\")\n",
    "else:\n",
    "    print(\"No icustay_id missing from vitals_windowed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32fd10dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "charttime   2 days 16:00:00\n",
       "dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the difference between max and min charttime for labs_windowed\n",
    "labs_diff = labs_windowed.groupby('icustay_id')['charttime'].apply(lambda x: x.max() - x.min()).to_frame()\n",
    "labs_diff.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0813a3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "charttime   2 days 23:00:00\n",
       "dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the difference between max and min charttime for vitals_windowed\n",
    "vitals_diff = vitals_windowed.groupby('icustay_id')['charttime'].apply(lambda x: x.max() - x.min()).to_frame()\n",
    "vitals_diff.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a436de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_LENGTH_NEW = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05406384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total :  8405\n",
      "0    7868\n",
      "1     537\n",
      "Name: ckd, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "filtered_icustay_ids = labs_diff[(labs_diff == pd.Timedelta(hours=WINDOW_LENGTH_NEW)) & (vitals_diff == pd.Timedelta(hours=WINDOW_LENGTH_NEW))].index.tolist()\n",
    "print(\"Total : \",len(filtered_icustay_ids))\n",
    "print(static_demo_comorb['ckd'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9857ba",
   "metadata": {},
   "source": [
    "## 2.1 Random Forest - Comorbidity & Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e91f0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestForMulti(X_train, X_test, y_train, y_test, resampling=None):        \n",
    "    if resampling == None:\n",
    "        print(\"No resampling: Train:\", y_train.shape[0] , \"Test:\", y_test.shape[0])        \n",
    "    elif resampling.lower() == 'under':\n",
    "        sampler = RandomUnderSampler()\n",
    "        X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "        print(\"under sampling: Train:\", y_train.shape[0] , \"Test:\", y_test.shape[0])\n",
    "    elif resampling.lower() == 'over':\n",
    "        sampler = SMOTE()\n",
    "        X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "        print(\"over sampling: Train:\", y_train.shape[0] , \"Test:\", y_test.shape[0])\n",
    "    \n",
    "    print(\"Distribution: Train:\", y_train.value_counts())\n",
    "    print(\"Distribution: Test :\", y_test.value_counts())\n",
    "        \n",
    "    rf_static_demo_comorb_best = RandomForestClassifier(n_estimators=200, \n",
    "                                                        max_depth=None,\n",
    "                                                        min_samples_leaf=2,\n",
    "                                                        min_samples_split=2,\n",
    "                                                        max_features='sqrt',\n",
    "                                                        random_state=42)\n",
    "    \n",
    "    rf_static_demo_comorb_best.fit(X_train, y_train)\n",
    "    \n",
    "    rf_static_demo_comorb_best, y_val = cross_val_with_sampling(rf_static_demo_comorb_best, X_train,y_train, resampling = resampling)\n",
    "    \n",
    "    y_pred = evaluationTest(rf_static_demo_comorb_best,X_test, y_test)\n",
    "    \n",
    "    #f1 = f1_score(y_test, y_pred)\n",
    "    #weight = np.log(f1/(1-f1))\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    weight = np.log(acc/(1-acc))  \n",
    "    \n",
    "    proba = rf_static_demo_comorb_best.predict_proba(X_test)\n",
    "    \n",
    "    return rf_static_demo_comorb_best, weight, proba    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7110e0",
   "metadata": {},
   "source": [
    "#### prepare training ids and test ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cac9b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=static_demo_comorb.drop(['ckd'],axis=1)\n",
    "y=static_demo_comorb['ckd']\n",
    "\n",
    "X_onehot=pd.get_dummies(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_onehot, y, test_size=0.2,stratify = y, random_state=42)\n",
    "\n",
    "test_ids_reuse = X_test['icustay_id']\n",
    "train_ids_reuse = X_train['icustay_id']\n",
    "\n",
    "X_train= X_train.drop(['icustay_id'],axis=1)\n",
    "X_test = X_test.drop(['icustay_id'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0d23d6",
   "metadata": {},
   "source": [
    "#### default Random Forest - Demographics + Comorbidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7824c27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resampling: Train: 6724 Test: 1681\n",
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "Name: ckd, dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "Name: ckd, dtype: int64\n",
      "CV : No resampling: Train: 5379 Test: 1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV : No resampling: Train: 5379 Test: 1345\n",
      "CV : No resampling: Train: 5379 Test: 1345\n",
      "CV : No resampling: Train: 5379 Test: 1345\n",
      "CV : No resampling: Train: 5380 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.94, 0.94, 0.94, 0.94, 0.94]\n",
      "CV:Recall   : [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "CV:F1-score : [0.97, 0.97, 0.97, 0.97, 0.97]\n",
      "\n",
      "CV:Precision Mean: 0.94\n",
      "CV:Recall Mean: 1.0\n",
      "CV:F1-score Mean: 0.97\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.0, 1.0, 0.33, 0.5, 1.0]\n",
      "CV:Recall   : [0.0, 0.03, 0.01, 0.01, 0.02]\n",
      "CV:F1-score : [0.0, 0.07, 0.02, 0.02, 0.05]\n",
      "\n",
      "CV:Precision Mean: 0.57\n",
      "CV:Recall Mean: 0.01\n",
      "CV:F1-score Mean: 0.03\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.94\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1574\n",
      "           1       0.00      0.00      0.00       107\n",
      "\n",
      "    accuracy                           0.94      1681\n",
      "   macro avg       0.47      0.50      0.48      1681\n",
      "weighted avg       0.88      0.94      0.91      1681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf_default, _, _ = RandomForestForMulti(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c924281a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under sampling: Train: 860 Test: 1681\n",
      "Distribution: Train: 0    430\n",
      "1    430\n",
      "Name: ckd, dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "Name: ckd, dtype: int64\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.66, 0.6, 0.62, 0.66, 0.65]\n",
      "CV:Recall   : [0.69, 0.72, 0.79, 0.76, 0.72]\n",
      "CV:F1-score : [0.67, 0.65, 0.7, 0.71, 0.68]\n",
      "\n",
      "CV:Precision Mean: 0.64\n",
      "CV:Recall Mean: 0.74\n",
      "CV:F1-score Mean: 0.68\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.67, 0.65, 0.71, 0.72, 0.68]\n",
      "CV:Recall   : [0.64, 0.51, 0.52, 0.62, 0.6]\n",
      "CV:F1-score : [0.65, 0.57, 0.6, 0.66, 0.64]\n",
      "\n",
      "CV:Precision Mean: 0.69\n",
      "CV:Recall Mean: 0.58\n",
      "CV:F1-score Mean: 0.62\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.66\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83      1574\n",
      "           1       0.12      0.56      0.20       107\n",
      "\n",
      "    accuracy                           0.72      1681\n",
      "   macro avg       0.54      0.65      0.52      1681\n",
      "weighted avg       0.91      0.72      0.79      1681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf_under_sampled, _, _ = RandomForestForMulti(X_train, X_test, y_train, y_test, resampling='under')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c47cd83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over sampling: Train: 12588 Test: 1681\n",
      "Distribution: Train: 0    6294\n",
      "1    6294\n",
      "Name: ckd, dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "Name: ckd, dtype: int64\n",
      "CV: Over sampling: Train: 10070 Test: 2518\n",
      "CV: Over sampling: Train: 10070 Test: 2518\n",
      "CV: Over sampling: Train: 10070 Test: 2518\n",
      "CV: Over sampling: Train: 10072 Test: 2517\n",
      "CV: Over sampling: Train: 10072 Test: 2517\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.67, 0.68, 0.68, 0.69, 0.68]\n",
      "CV:Recall   : [0.78, 0.78, 0.74, 0.69, 0.71]\n",
      "CV:F1-score : [0.72, 0.73, 0.71, 0.69, 0.7]\n",
      "\n",
      "CV:Precision Mean: 0.68\n",
      "CV:Recall Mean: 0.74\n",
      "CV:F1-score Mean: 0.71\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.74, 0.74, 0.71, 0.69, 0.7]\n",
      "CV:Recall   : [0.61, 0.64, 0.64, 0.69, 0.66]\n",
      "CV:F1-score : [0.67, 0.68, 0.68, 0.69, 0.68]\n",
      "\n",
      "CV:Precision Mean: 0.72\n",
      "CV:Recall Mean: 0.65\n",
      "CV:F1-score Mean: 0.68\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.7\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.72      0.82      1574\n",
      "           1       0.10      0.48      0.17       107\n",
      "\n",
      "    accuracy                           0.71      1681\n",
      "   macro avg       0.53      0.60      0.50      1681\n",
      "weighted avg       0.90      0.71      0.78      1681\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\navim\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rf_over_sampled, _, _ = RandomForestForMulti(X_train, X_test, y_train, y_test, resampling='over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3687311",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregated Static model\n",
    "\n",
    "#merged_table_agg=merged_table.drop(['subject_id','hadm_id','dod','admittime', 'dischtime','los_hospital','ethnicity','hospital_expire_flag','hospstay_seq', 'first_hosp_stay', 'intime','outtime', 'los_icu', 'icustay_seq', 'first_icu_stay_current_hosp','first_icu_stay_patient', 'first_careunit', 'deathtime_icu','label_death_icu', 'predtime', 'delta_t_pred'],axis=1)\n",
    "#\n",
    "#ethnicities_to_drop = [\"middle_eastern\", \"portuguese\", \"alaska_native\", \"pacific_islander\"]\n",
    "#merged_table_agg    = merged_table_agg[~merged_table_agg['ethnicity_grouped'].isin(ethnicities_to_drop)]\n",
    "\n",
    "#X=merged_table_agg.drop(['ckd'],axis=1)\n",
    "#y=merged_table_agg['ckd']\n",
    "#\n",
    "#X_onehot=pd.get_dummies(X)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_onehot, y, test_size=0.2,stratify = y, random_state=42)\n",
    "#\n",
    "#test_ids_reuse = X_test['icustay_id']\n",
    "#\n",
    "#X_train= X_train.drop(['icustay_id'],axis=1)\n",
    "#X_test = X_test.drop(['icustay_id'],axis=1)\n",
    "\n",
    "#rf_default_agg, _, _ = RandomForestForMulti(X_train, X_test, y_train, y_test)\n",
    "\n",
    "#rf_under_agg, _, _ = RandomForestForMulti(X_train, X_test, y_train, y_test, resampling='under')\n",
    "\n",
    "#rf_over_agg, _, _ = RandomForestForMulti(X_train, X_test, y_train, y_test, resampling='over')\n",
    "\n",
    "#X_train_no_eth= X_train.drop(['ethnicity_grouped_asian','ethnicity_grouped_black',   'ethnicity_grouped_hispanic', \n",
    "#'ethnicity_grouped_unknown', 'ethnicity_grouped_white'],axis=1)\n",
    "#\n",
    "#X_test_no_eth= X_test.drop(['ethnicity_grouped_asian','ethnicity_grouped_black',   'ethnicity_grouped_hispanic', \n",
    "#'ethnicity_grouped_unknown', 'ethnicity_grouped_white'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7601c60",
   "metadata": {},
   "source": [
    "## 2.2 Time series - Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f51e5663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_unique_shape(grouped_data,feature_cols):\n",
    "    previous_shape = []\n",
    "    for _, group in grouped_data:\n",
    "        group_values = group[feature_cols].values.T\n",
    "        if group_values.shape not in previous_shape:        \n",
    "            print(group_values.shape)\n",
    "            previous_shape.append(group_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75067c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_shape_in_grouped_df(data_grouped, feature_cols, icustay_id):\n",
    "    for _, group in data_grouped:\n",
    "        if(group['icustay_id'].values[0]==icustay_id):\n",
    "            group_values = group[feature_cols].values.T\n",
    "            return group_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4e0eb7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_missing_and_extras(data_windowed,feature_cols, threshold):\n",
    "    data_windowed_new = data_windowed.copy()\n",
    "    df_counts = data_windowed_new.groupby('icustay_id').count()\n",
    "    previous_shape = []\n",
    "    \n",
    "    icustay_ids_less_records = df_counts[df_counts['charttime'] < threshold].index\n",
    "    icustay_ids_more_records = df_counts[df_counts['charttime'] > threshold].index\n",
    "    icustay_ids_correct_records = df_counts[df_counts['charttime'] == threshold].index\n",
    "     \n",
    "    print(\"len(icustay_ids_fewer_records)\",len(icustay_ids_less_records))\n",
    "    print(\"len(icustay_ids_more_records)\",len(icustay_ids_more_records))  \n",
    "    print(\"len(icustay_ids_correct_records)\",len(icustay_ids_correct_records))\n",
    "        \n",
    "    for icustay_id in icustay_ids_more_records:\n",
    "        df_grouped = data_windowed_new[data_windowed_new['icustay_id'] == icustay_id]\n",
    "        if df_grouped.shape not in previous_shape:        \n",
    "            print(f\"There are records with more than {threshold} readings : {df_grouped.shape}\")\n",
    "            previous_shape.append(df_grouped.shape)\n",
    "        \n",
    "        # Check if the time span is more than 4 days\n",
    "        if (df_grouped['charttime'].max() - df_grouped['charttime'].min()).days > 4:\n",
    "            print(f\"icustay_id: {icustay_id} has a time span of more than 4 days.\")\n",
    "        \n",
    "        # Check for duplicate records\n",
    "        if df_grouped.duplicated().sum() > 0:\n",
    "            print(f\"icustay_id: {icustay_id} has {df_grouped.duplicated().sum()} duplicate records.\")\n",
    "            \n",
    "    for icustay_id in icustay_ids_less_records:\n",
    "        print(f\"icustay_id: {icustay_id} has a time span less than {threshold} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "138fa4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_forward_fill(data_windowed, time_interval, threshold, feature_cols):    \n",
    "    data_windowed_new = data_windowed.copy()\n",
    "    data_windowed_new['charttime'] = pd.to_datetime(data_windowed_new['charttime']) \n",
    "    data_windowed_new.sort_values(['icustay_id', 'charttime'])\n",
    "    df_filled = data_windowed_new.groupby('icustay_id').apply(lambda group: group.bfill().ffill())\n",
    "    return df_filled    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbbd4d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_threshold_records(df, time_interval, threshold, feature_cols):\n",
    "    df_new = pd.DataFrame()\n",
    "    for id, group in df.groupby('icustay_id'):\n",
    "        if len(group) > threshold:\n",
    "            group = group.head(threshold)\n",
    "        elif len(group) < threshold:\n",
    "            missing_rows_count = threshold - len(group)\n",
    "            last_timestamp = group['charttime'].max()\n",
    "            missing_rows_df = pd.DataFrame({\n",
    "                'icustay_id': [id]*missing_rows_count,\n",
    "                'charttime': pd.date_range(start=last_timestamp + pd.Timedelta(hours=time_interval), \n",
    "                                           periods=missing_rows_count, \n",
    "                                           freq=f'{time_interval}H'),\n",
    "                'ckd': [group['ckd'].iloc[0]]*missing_rows_count\n",
    "            })\n",
    "            for col in feature_cols:\n",
    "                missing_rows_df[col] = np.nan\n",
    "            group = pd.concat([group, missing_rows_df])\n",
    "        df_new = pd.concat([df_new, group])\n",
    "    df_new.sort_values(['icustay_id', 'charttime'], inplace=True)\n",
    "    df_new.reset_index(drop=True, inplace=True)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36880372",
   "metadata": {},
   "source": [
    "### 2.2.1 Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "136b7027",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labs= ['aniongap', 'albumin', 'bands',\n",
    "       'bicarbonate', 'bilirubin', 'creatinine', 'chloride', 'glucose',\n",
    "       'hematocrit', 'hemoglobin', 'lactate', 'platelet', 'potassium', 'ptt',\n",
    "       'inr', 'pt', 'sodium', 'bun', 'wbc', 'bacteria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "025aff5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navim\\AppData\\Local\\Temp\\ipykernel_18480\\2008068236.py:5: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_filled = data_windowed_new.groupby('icustay_id').apply(lambda group: group.bfill().ffill())\n"
     ]
    }
   ],
   "source": [
    "labs_windowed_12 = create_threshold_records(labs_windowed, 8, 12, feature_labs)\n",
    "labs_windowed_12 = backward_forward_fill(labs_windowed_12, 8, 12, feature_labs)\n",
    "\n",
    "labs_windowed_12['charttime'] = pd.to_datetime(labs_windowed_12['charttime']) \n",
    "labs_windowed_12.sort_values(['icustay_id', 'charttime'])\n",
    "labs_grouped = labs_windowed_12[['icustay_id'] + feature_labs + ['ckd']].groupby(['icustay_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2d3e819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(icustay_ids_fewer_records) 0\n",
      "len(icustay_ids_more_records) 0\n",
      "len(icustay_ids_correct_records) 8405\n"
     ]
    }
   ],
   "source": [
    "check_missing_and_extras(labs_windowed_12,feature_labs, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "336df055",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navim\\AppData\\Local\\Temp\\ipykernel_18480\\1028510881.py:3: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for _, group in grouped_data:\n"
     ]
    }
   ],
   "source": [
    "print_unique_shape(labs_grouped,feature_labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc482910",
   "metadata": {},
   "source": [
    "### 2.2.2 Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6a13a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navim\\AppData\\Local\\Temp\\ipykernel_18480\\2008068236.py:5: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_filled = data_windowed_new.groupby('icustay_id').apply(lambda group: group.bfill().ffill())\n"
     ]
    }
   ],
   "source": [
    "feature_vitals = ['heartrate', 'sysbp', 'diasbp', 'meanbp', 'resprate', \n",
    "                  'tempc', 'spo2', 'glucose', 'rbc', 'specificgravity', 'appetite_median']\n",
    "\n",
    "vitals_windowed_96 = create_threshold_records(vitals_windowed, 1, 96, feature_vitals)\n",
    "vitals_windowed_96 = backward_forward_fill(vitals_windowed_96, 1, 96, feature_vitals)\n",
    "\n",
    "vitals_windowed_96['charttime'] = pd.to_datetime(vitals_windowed_96['charttime']) \n",
    "vitals_windowed_96.sort_values(['icustay_id', 'charttime'])\n",
    "vitals_grouped = vitals_windowed_96[['icustay_id'] + feature_vitals + ['ckd']].groupby(['icustay_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6f7e1c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(icustay_ids_fewer_records) 0\n",
      "len(icustay_ids_more_records) 0\n",
      "len(icustay_ids_correct_records) 8405\n"
     ]
    }
   ],
   "source": [
    "check_missing_and_extras(vitals_windowed_96,feature_vitals, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d4f71f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navim\\AppData\\Local\\Temp\\ipykernel_18480\\1028510881.py:3: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for _, group in grouped_data:\n"
     ]
    }
   ],
   "source": [
    "print_unique_shape(vitals_grouped,feature_vitals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cebc92",
   "metadata": {},
   "source": [
    "## 2.3 Rocket - Time series model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb52f2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labs_grouped['icustay_id'].nunique():  8405\n",
      "vitals_grouped['icustay_id'].nunique():  8405\n"
     ]
    }
   ],
   "source": [
    "print(\"labs_grouped['icustay_id'].nunique(): \",len(labs_grouped['icustay_id'].nunique()))\n",
    "print(\"vitals_grouped['icustay_id'].nunique(): \",len(vitals_grouped['icustay_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43aa8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_with_sampling_timeseries(clf, X, y, Xt, resampling=None):\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        \n",
    "    label0_prec=[]\n",
    "    label0_rec=[]\n",
    "    label0_f1=[]   \n",
    "    label1_prec=[]\n",
    "    label1_rec=[]\n",
    "    label1_f1=[]   \n",
    "    acc_val=[]\n",
    "    \n",
    "    for train_index, test_index in kfold.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Reshape the training data\n",
    "        n_samples_train, n_features_train, n_channels_train = X_train.shape\n",
    "        X_train_2d = X_train.reshape((n_samples_train, n_features_train * n_channels_train))\n",
    "        \n",
    "        if resampling is None:\n",
    "            print(\"No resampling: Train:\", y_train.shape[0], \"Test:\", y_test.shape[0])\n",
    "            X_train_resampled = X_train_2d\n",
    "            y_train_resampled = y_train\n",
    "        elif resampling.lower() == 'under':\n",
    "            sampler = RandomUnderSampler(random_state=42)\n",
    "            X_train_resampled, y_train_resampled = sampler.fit_resample(X_train_2d, y_train)\n",
    "            print(\"Under sampling: Train:\", y_train_resampled.shape[0], \"Test:\", y_test.shape[0])\n",
    "        elif resampling.lower() == 'over':\n",
    "            sampler = SMOTE(random_state=42)\n",
    "            X_train_resampled, y_train_resampled = sampler.fit_resample(X_train_2d, y_train)\n",
    "            print(\"Over sampling: Train:\", y_train_resampled.shape[0], \"Test:\", y_test.shape[0])\n",
    "        \n",
    "        # Reshape the resampled training data\n",
    "        X_train_resampled = X_train_resampled.reshape((X_train_resampled.shape[0], n_features_train, n_channels_train))\n",
    "        y_train_resampled = y_train_resampled\n",
    "        \n",
    "        rocket = Rocket(num_kernels=100, random_state=42)\n",
    "        rocket.fit(X_train_resampled)\n",
    "        X_train_transformed = rocket.transform(X_train_resampled)\n",
    "        X_test_transformed = rocket.transform(X_test)\n",
    "    \n",
    "        clf.fit(X_train_transformed, y_train_resampled)\n",
    "        \n",
    "        y_pred_validation = clf.predict(X_test_transformed)        \n",
    "        \n",
    "        clf_res=classification_report(y_test,y_pred_validation,output_dict=True)\n",
    "        label0, label1, acc=(clf_res['0'],clf_res['1'],clf_res['accuracy'])\n",
    "        \n",
    "        label0_prec.append(round(label0['precision'], 2))\n",
    "        label0_rec.append(round(label0['recall'], 2))\n",
    "        label0_f1.append(round(label0['f1-score'], 2))        \n",
    "        label1_prec.append(round(label1['precision'], 2))\n",
    "        label1_rec.append(round(label1['recall'], 2))\n",
    "        label1_f1.append(round(label1['f1-score'], 2))        \n",
    "        acc_val.append(round(acc, 2))\n",
    "        \n",
    "    print(\"---------CV : Label 0----------------\")\n",
    "    print(\"CV:Precision: \",label0_prec)   \n",
    "    print(\"CV:Recall   :\",label0_rec)\n",
    "    print(\"CV:F1-score :\",label0_f1)\n",
    "    \n",
    "    print(\"\\nCV:Precision Mean:\",round(statistics.mean(label0_prec), 2))\n",
    "    print(\"CV:Recall Mean:\",round(statistics.mean(label0_rec), 2))\n",
    "    print(\"CV:F1-score Mean:\",round(statistics.mean(label0_f1), 2))                        \n",
    "                         \n",
    "    print(\"---------CV : Label 1----------------\")\n",
    "    print(\"CV:Precision: \",label1_prec)\n",
    "    print(\"CV:Recall   :\",label1_rec)\n",
    "    print(\"CV:F1-score :\",label1_f1)\n",
    "    \n",
    "    print(\"\\nCV:Precision Mean:\",round(statistics.mean(label1_prec), 2))\n",
    "    print(\"CV:Recall Mean:\",round(statistics.mean(label1_rec), 2))\n",
    "    print(\"CV:F1-score Mean:\",round(statistics.mean(label1_f1), 2))\n",
    "    print(\"---------Accuracy CV----------------\")\n",
    "    print(\"CV: Accuracy \",round(statistics.mean(acc_val), 2))\n",
    "    print(\"------------------------------------\")\n",
    "    Xt_transformed = rocket.transform(Xt)\n",
    "    \n",
    "    return clf, y_pred_validation, Xt_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48ecdb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RocketMulti(grouped_data,feature_columns, num_kernels=100, resampling=None, filtered_train_ids = None, filtered_test_ids = None):  \n",
    "    import warnings\n",
    "    import logging\n",
    "    warnings.filterwarnings('ignore')   \n",
    "    logging.getLogger().setLevel(logging.ERROR)\n",
    "    \n",
    "    if filtered_test_ids is None:\n",
    "        X = []\n",
    "        y = []\n",
    "    else:\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "        X_test = []\n",
    "        y_test = []\n",
    "                        \n",
    "    for icustay_id, group in grouped_data:\n",
    "        group_values = group[feature_columns].values.T\n",
    "        num_timestamps = group_values.shape[1]\n",
    "        \n",
    "        if filtered_test_ids is None:\n",
    "            X.append(group_values)\n",
    "            y.append(group['ckd'].iloc[0])\n",
    "        else:\n",
    "            if filtered_test_ids.isin([icustay_id]).any():               \n",
    "                X_test.append(group_values)\n",
    "                y_test.append(group['ckd'].iloc[0])\n",
    "            elif filtered_train_ids.isin([icustay_id]).any():\n",
    "                X_train.append(group_values)\n",
    "                y_train.append(group['ckd'].iloc[0])\n",
    "        \n",
    "    clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    \n",
    "    y_test_series = pd.Series(y_test)\n",
    "    y_train_series = pd.Series(y_train)\n",
    "    print(\"Distribution: Train:\", y_train_series.value_counts())\n",
    "    print(\"Distribution: Test :\", y_test_series.value_counts())\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)    \n",
    "    \n",
    "    clf, _ , X_test_transformed_2d = cross_val_with_sampling_timeseries(clf, X_train, y_train, X_test, resampling=resampling)\n",
    "    \n",
    "    y_pred = evaluationTest(clf,X_test_transformed_2d, y_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    weight = np.log(acc/(1-acc))     \n",
    "    proba = clf.predict_proba(X_test_transformed_2d)\n",
    "    \n",
    "    return clf, weight, proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462fc473",
   "metadata": {},
   "source": [
    "### 2.3.1 Rocket for Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e733798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "No resampling: Train: 5379 Test: 1345\n",
      "No resampling: Train: 5379 Test: 1345\n",
      "No resampling: Train: 5379 Test: 1345\n",
      "No resampling: Train: 5379 Test: 1345\n",
      "No resampling: Train: 5380 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.94, 0.94, 0.94, 0.94, 0.94]\n",
      "CV:Recall   : [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "CV:F1-score : [0.96, 0.97, 0.97, 0.97, 0.97]\n",
      "\n",
      "CV:Precision Mean: 0.94\n",
      "CV:Recall Mean: 1.0\n",
      "CV:F1-score Mean: 0.97\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.0, 0.0, 0.33, 0.0, 0.17]\n",
      "CV:Recall   : [0.0, 0.0, 0.01, 0.0, 0.01]\n",
      "CV:F1-score : [0.0, 0.0, 0.02, 0.0, 0.02]\n",
      "\n",
      "CV:Precision Mean: 0.1\n",
      "CV:Recall Mean: 0.0\n",
      "CV:F1-score Mean: 0.01\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.94\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1574\n",
      "           1       0.33      0.01      0.02       107\n",
      "\n",
      "    accuracy                           0.94      1681\n",
      "   macro avg       0.64      0.50      0.49      1681\n",
      "weighted avg       0.90      0.94      0.91      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_lab_default, _, _ = RocketMulti(labs_grouped,feature_labs, filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b4f0ca",
   "metadata": {},
   "source": [
    "#### 2.3.1.1 Undersampling -labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ecfc9fb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.96, 0.95, 0.97, 0.96, 0.95]\n",
      "CV:Recall   : [0.6, 0.61, 0.59, 0.61, 0.58]\n",
      "CV:F1-score : [0.74, 0.74, 0.74, 0.75, 0.72]\n",
      "\n",
      "CV:Precision Mean: 0.96\n",
      "CV:Recall Mean: 0.6\n",
      "CV:F1-score Mean: 0.74\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.1, 0.08, 0.11, 0.1, 0.09]\n",
      "CV:Recall   : [0.65, 0.53, 0.77, 0.65, 0.57]\n",
      "CV:F1-score : [0.17, 0.15, 0.2, 0.18, 0.15]\n",
      "\n",
      "CV:Precision Mean: 0.1\n",
      "CV:Recall Mean: 0.63\n",
      "CV:F1-score Mean: 0.17\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.6\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.61      0.75      1574\n",
      "           1       0.09      0.59      0.16       107\n",
      "\n",
      "    accuracy                           0.61      1681\n",
      "   macro avg       0.52      0.60      0.45      1681\n",
      "weighted avg       0.90      0.61      0.71      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_lab_under_sampled_default, _, _ = RocketMulti(labs_grouped,feature_labs, resampling = \"Under\", filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31475737",
   "metadata": {},
   "source": [
    "#### Without Albumin & Creatinine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33587890",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labs_no_alcr= ['aniongap', 'bands',\n",
    "       'bicarbonate', 'bilirubin', 'chloride', 'glucose',\n",
    "       'hematocrit', 'hemoglobin', 'lactate', 'platelet', 'potassium', 'ptt',\n",
    "       'inr', 'pt', 'sodium', 'bun', 'wbc', 'bacteria']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4d7245f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.96, 0.97, 0.96, 0.96, 0.95]\n",
      "CV:Recall   : [0.6, 0.6, 0.59, 0.61, 0.6]\n",
      "CV:F1-score : [0.74, 0.74, 0.73, 0.74, 0.74]\n",
      "\n",
      "CV:Precision Mean: 0.96\n",
      "CV:Recall Mean: 0.6\n",
      "CV:F1-score Mean: 0.74\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.1, 0.11, 0.1, 0.1, 0.09]\n",
      "CV:Recall   : [0.64, 0.71, 0.66, 0.66, 0.55]\n",
      "CV:F1-score : [0.17, 0.19, 0.17, 0.18, 0.15]\n",
      "\n",
      "CV:Precision Mean: 0.1\n",
      "CV:Recall Mean: 0.64\n",
      "CV:F1-score Mean: 0.17\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.6\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.60      0.74      1574\n",
      "           1       0.10      0.64      0.17       107\n",
      "\n",
      "    accuracy                           0.61      1681\n",
      "   macro avg       0.53      0.62      0.46      1681\n",
      "weighted avg       0.91      0.61      0.71      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_lab_under_no_alcr, _, _ = RocketMulti(labs_grouped, feature_labs_no_alcr, resampling = \"Under\", filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421d887",
   "metadata": {},
   "source": [
    "#### With only Albumin & Creatinine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee8a9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_labs_alcr= ['albumin','creatinine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12c632b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.96, 0.96, 0.97, 0.96, 0.96]\n",
      "CV:Recall   : [0.55, 0.61, 0.61, 0.6, 0.59]\n",
      "CV:F1-score : [0.7, 0.74, 0.75, 0.73, 0.73]\n",
      "\n",
      "CV:Precision Mean: 0.96\n",
      "CV:Recall Mean: 0.59\n",
      "CV:F1-score Mean: 0.73\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.1, 0.1, 0.11, 0.09, 0.09]\n",
      "CV:Recall   : [0.7, 0.64, 0.71, 0.6, 0.62]\n",
      "CV:F1-score : [0.17, 0.17, 0.19, 0.16, 0.16]\n",
      "\n",
      "CV:Precision Mean: 0.1\n",
      "CV:Recall Mean: 0.65\n",
      "CV:F1-score Mean: 0.17\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.59\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.59      0.73      1574\n",
      "           1       0.10      0.68      0.18       107\n",
      "\n",
      "    accuracy                           0.60      1681\n",
      "   macro avg       0.53      0.64      0.45      1681\n",
      "weighted avg       0.91      0.60      0.70      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_lab_under_alcr, _, _ = RocketMulti(labs_grouped, feature_labs_alcr, resampling = \"Under\", filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505e202",
   "metadata": {},
   "source": [
    "#### 2.3.1.2 Oversampling - labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "11423e46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10072 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.96, 0.95, 0.96, 0.95, 0.95]\n",
      "CV:Recall   : [0.75, 0.76, 0.75, 0.75, 0.75]\n",
      "CV:F1-score : [0.84, 0.84, 0.84, 0.84, 0.84]\n",
      "\n",
      "CV:Precision Mean: 0.95\n",
      "CV:Recall Mean: 0.75\n",
      "CV:F1-score Mean: 0.84\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.12, 0.1, 0.12, 0.1, 0.11]\n",
      "CV:Recall   : [0.49, 0.41, 0.49, 0.4, 0.47]\n",
      "CV:F1-score : [0.19, 0.16, 0.19, 0.16, 0.18]\n",
      "\n",
      "CV:Precision Mean: 0.11\n",
      "CV:Recall Mean: 0.45\n",
      "CV:F1-score Mean: 0.18\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.73\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84      1574\n",
      "           1       0.10      0.43      0.17       107\n",
      "\n",
      "    accuracy                           0.73      1681\n",
      "   macro avg       0.53      0.59      0.50      1681\n",
      "weighted avg       0.90      0.73      0.80      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_lab_over_sampled_default, _, _ = RocketMulti(labs_grouped,feature_labs, resampling = \"Over\", filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45390ff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10072 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.96, 0.95, 0.96, 0.95, 0.95]\n",
      "CV:Recall   : [0.75, 0.76, 0.75, 0.75, 0.75]\n",
      "CV:F1-score : [0.84, 0.84, 0.84, 0.84, 0.84]\n",
      "\n",
      "CV:Precision Mean: 0.95\n",
      "CV:Recall Mean: 0.75\n",
      "CV:F1-score Mean: 0.84\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.12, 0.1, 0.12, 0.1, 0.11]\n",
      "CV:Recall   : [0.49, 0.41, 0.49, 0.4, 0.47]\n",
      "CV:F1-score : [0.19, 0.16, 0.19, 0.16, 0.18]\n",
      "\n",
      "CV:Precision Mean: 0.11\n",
      "CV:Recall Mean: 0.45\n",
      "CV:F1-score Mean: 0.18\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.73\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.75      0.84      1574\n",
      "           1       0.10      0.43      0.17       107\n",
      "\n",
      "    accuracy                           0.73      1681\n",
      "   macro avg       0.53      0.59      0.50      1681\n",
      "weighted avg       0.90      0.73      0.80      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_lab_over_sampled_75, _, _ = RocketMulti(labs_grouped,feature_labs, num_kernels = 75, resampling = \"Over\", filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd5ca8",
   "metadata": {},
   "source": [
    "### 2.3.2 Rocket for Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7173dcfe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "No resampling: Train: 5379 Test: 1345\n",
      "No resampling: Train: 5379 Test: 1345\n",
      "No resampling: Train: 5379 Test: 1345\n",
      "No resampling: Train: 5379 Test: 1345\n",
      "No resampling: Train: 5380 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.94, 0.94, 0.94, 0.94, 0.94]\n",
      "CV:Recall   : [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "CV:F1-score : [0.97, 0.97, 0.97, 0.97, 0.97]\n",
      "\n",
      "CV:Precision Mean: 0.94\n",
      "CV:Recall Mean: 1.0\n",
      "CV:F1-score Mean: 0.97\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "CV:Recall   : [0.0, 0.0, 0.0, 0.01, 0.0]\n",
      "CV:F1-score : [0.0, 0.0, 0.0, 0.02, 0.0]\n",
      "\n",
      "CV:Precision Mean: 0.2\n",
      "CV:Recall Mean: 0.0\n",
      "CV:F1-score Mean: 0.0\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.94\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      1574\n",
      "           1       0.00      0.00      0.00       107\n",
      "\n",
      "    accuracy                           0.94      1681\n",
      "   macro avg       0.47      0.50      0.48      1681\n",
      "weighted avg       0.88      0.94      0.91      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_vitals_default, _, _ = RocketMulti(vitals_grouped,feature_vitals, filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69bcb71",
   "metadata": {},
   "source": [
    "#### 2.3.2.1 Undersampling - Vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5179dc32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.96, 0.96, 0.96, 0.97, 0.96]\n",
      "CV:Recall   : [0.57, 0.57, 0.6, 0.58, 0.59]\n",
      "CV:F1-score : [0.71, 0.72, 0.74, 0.73, 0.73]\n",
      "\n",
      "CV:Precision Mean: 0.96\n",
      "CV:Recall Mean: 0.58\n",
      "CV:F1-score Mean: 0.73\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.1, 0.09, 0.09, 0.11, 0.1]\n",
      "CV:Recall   : [0.7, 0.64, 0.62, 0.73, 0.64]\n",
      "CV:F1-score : [0.17, 0.16, 0.16, 0.19, 0.17]\n",
      "\n",
      "CV:Precision Mean: 0.1\n",
      "CV:Recall Mean: 0.67\n",
      "CV:F1-score Mean: 0.17\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.58\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.61      0.75      1574\n",
      "           1       0.10      0.67      0.18       107\n",
      "\n",
      "    accuracy                           0.61      1681\n",
      "   macro avg       0.53      0.64      0.46      1681\n",
      "weighted avg       0.91      0.61      0.71      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_vitals_under_sampled_default, _, _ = RocketMulti(vitals_grouped,feature_vitals, resampling=\"Under\", filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d23c9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.96, 0.96, 0.96, 0.97, 0.96]\n",
      "CV:Recall   : [0.57, 0.57, 0.6, 0.58, 0.59]\n",
      "CV:F1-score : [0.71, 0.72, 0.74, 0.73, 0.73]\n",
      "\n",
      "CV:Precision Mean: 0.96\n",
      "CV:Recall Mean: 0.58\n",
      "CV:F1-score Mean: 0.73\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.1, 0.09, 0.09, 0.11, 0.1]\n",
      "CV:Recall   : [0.7, 0.64, 0.62, 0.73, 0.64]\n",
      "CV:F1-score : [0.17, 0.16, 0.16, 0.19, 0.17]\n",
      "\n",
      "CV:Precision Mean: 0.1\n",
      "CV:Recall Mean: 0.67\n",
      "CV:F1-score Mean: 0.17\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.58\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.61      0.75      1574\n",
      "           1       0.10      0.67      0.18       107\n",
      "\n",
      "    accuracy                           0.61      1681\n",
      "   macro avg       0.53      0.64      0.46      1681\n",
      "weighted avg       0.91      0.61      0.71      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_vitals_under_sampled_75, _, _ = RocketMulti(vitals_grouped,feature_vitals, num_kernels = 75, resampling = \"Under\", filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfef87f",
   "metadata": {},
   "source": [
    "#### 2.3.2.2 oversamplimg for vitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f4d1c816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10072 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.96, 0.96, 0.95, 0.96, 0.95]\n",
      "CV:Recall   : [0.71, 0.7, 0.7, 0.72, 0.73]\n",
      "CV:F1-score : [0.81, 0.81, 0.8, 0.82, 0.83]\n",
      "\n",
      "CV:Precision Mean: 0.96\n",
      "CV:Recall Mean: 0.71\n",
      "CV:F1-score Mean: 0.81\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.12, 0.11, 0.08, 0.12, 0.11]\n",
      "CV:Recall   : [0.6, 0.56, 0.41, 0.56, 0.47]\n",
      "CV:F1-score : [0.2, 0.19, 0.14, 0.2, 0.17]\n",
      "\n",
      "CV:Precision Mean: 0.11\n",
      "CV:Recall Mean: 0.52\n",
      "CV:F1-score Mean: 0.18\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.7\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83      1574\n",
      "           1       0.12      0.53      0.19       107\n",
      "\n",
      "    accuracy                           0.72      1681\n",
      "   macro avg       0.54      0.63      0.51      1681\n",
      "weighted avg       0.90      0.72      0.79      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_vitals_over_sampled_default, _, _ = RocketMulti(vitals_grouped,feature_vitals, resampling = \"Over\", filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6ae30c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10072 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.96, 0.96, 0.95, 0.96, 0.95]\n",
      "CV:Recall   : [0.71, 0.7, 0.7, 0.72, 0.73]\n",
      "CV:F1-score : [0.81, 0.81, 0.8, 0.82, 0.83]\n",
      "\n",
      "CV:Precision Mean: 0.96\n",
      "CV:Recall Mean: 0.71\n",
      "CV:F1-score Mean: 0.81\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.12, 0.11, 0.08, 0.12, 0.11]\n",
      "CV:Recall   : [0.6, 0.56, 0.41, 0.56, 0.47]\n",
      "CV:F1-score : [0.2, 0.19, 0.14, 0.2, 0.17]\n",
      "\n",
      "CV:Precision Mean: 0.11\n",
      "CV:Recall Mean: 0.52\n",
      "CV:F1-score Mean: 0.18\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.7\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83      1574\n",
      "           1       0.12      0.53      0.19       107\n",
      "\n",
      "    accuracy                           0.72      1681\n",
      "   macro avg       0.54      0.63      0.51      1681\n",
      "weighted avg       0.90      0.72      0.79      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_vitals_over_sampled_75, _, _ = RocketMulti(vitals_grouped,feature_vitals, num_kernels = 75, resampling = \"Over\", filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd34a6f",
   "metadata": {},
   "source": [
    "## Demographics without ethnicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5631f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_no_eth=X_train.drop(['ethnicity_grouped_alaska_native',\n",
    "                             'ethnicity_grouped_asian',\n",
    "                             'ethnicity_grouped_black',\n",
    "                             'ethnicity_grouped_hispanic',\n",
    "                            'ethnicity_grouped_middle_eastern']\n",
    "                            ,axis=1)\n",
    "X_test_no_eth=X_test.drop(['ethnicity_grouped_alaska_native',\n",
    "                             'ethnicity_grouped_asian',\n",
    "                             'ethnicity_grouped_black',\n",
    "                             'ethnicity_grouped_hispanic',\n",
    "                            'ethnicity_grouped_middle_eastern']\n",
    "                            ,axis=1)\n",
    "\n",
    "X_train_no_eth_onehot = pd.get_dummies(X_train_no_eth)\n",
    "X_test_no_eth_onehot = pd.get_dummies(X_test_no_eth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d6bc982a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under sampling: Train: 860 Test: 1681\n",
      "Distribution: Train: 0    430\n",
      "1    430\n",
      "Name: ckd, dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "Name: ckd, dtype: int64\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.61, 0.59, 0.58, 0.58, 0.59]\n",
      "CV:Recall   : [0.66, 0.78, 0.64, 0.6, 0.73]\n",
      "CV:F1-score : [0.64, 0.67, 0.61, 0.59, 0.65]\n",
      "\n",
      "CV:Precision Mean: 0.59\n",
      "CV:Recall Mean: 0.68\n",
      "CV:F1-score Mean: 0.63\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.63, 0.67, 0.6, 0.59, 0.65]\n",
      "CV:Recall   : [0.58, 0.45, 0.53, 0.56, 0.49]\n",
      "CV:F1-score : [0.61, 0.54, 0.56, 0.57, 0.56]\n",
      "\n",
      "CV:Precision Mean: 0.63\n",
      "CV:Recall Mean: 0.52\n",
      "CV:F1-score Mean: 0.57\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.6\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85      1574\n",
      "           1       0.13      0.53      0.21       107\n",
      "\n",
      "    accuracy                           0.74      1681\n",
      "   macro avg       0.54      0.65      0.53      1681\n",
      "weighted avg       0.91      0.74      0.81      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_demo_noeth, _ , _ = RandomForestForMulti(X_train_no_eth_onehot, X_test_no_eth_onehot, y_train, y_test, resampling='under')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f37fa6",
   "metadata": {},
   "source": [
    "## 2.4 Multimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cf7fd42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_voting(clf_static, clf_lab, clf_vital, weight_static, weight_lab, weight_vital,\n",
    "               prob_static, prob_lab, prob_vital, y_test):\n",
    "    \n",
    "    #weights = np.array([weight_static, weight_lab, weight_vital])\n",
    "    #shift_positive = abs(weights.min()) + 2\n",
    "    #weight_static += shift_positive\n",
    "    #weight_lab += shift_positive\n",
    "    #weight_vital += shift_positive\n",
    "    \n",
    "    weighted_prob = ((weight_static * prob_static) +  (weight_lab * prob_lab) + (weight_vital * prob_vital)) / np.sum([weight_static, weight_lab, weight_vital])\n",
    "\n",
    "    y_pred = np.argmax(weighted_prob, axis=1)\n",
    "    \n",
    "    metricsReport(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08124c6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under sampling: Train: 860 Test: 1681\n",
      "Distribution: Train: 0    430\n",
      "1    430\n",
      "Name: ckd, dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "Name: ckd, dtype: int64\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "CV: Under sampling: Train: 688 Test: 172\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.63, 0.6, 0.62, 0.64, 0.6]\n",
      "CV:Recall   : [0.64, 0.69, 0.79, 0.63, 0.7]\n",
      "CV:F1-score : [0.64, 0.64, 0.69, 0.63, 0.65]\n",
      "\n",
      "CV:Precision Mean: 0.62\n",
      "CV:Recall Mean: 0.69\n",
      "CV:F1-score Mean: 0.65\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.64, 0.63, 0.71, 0.63, 0.64]\n",
      "CV:Recall   : [0.63, 0.53, 0.51, 0.64, 0.53]\n",
      "CV:F1-score : [0.63, 0.58, 0.59, 0.64, 0.58]\n",
      "\n",
      "CV:Precision Mean: 0.65\n",
      "CV:Recall Mean: 0.57\n",
      "CV:F1-score Mean: 0.6\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.63\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83      1574\n",
      "           1       0.13      0.58      0.21       107\n",
      "\n",
      "    accuracy                           0.72      1681\n",
      "   macro avg       0.54      0.65      0.52      1681\n",
      "weighted avg       0.91      0.72      0.79      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Best model for static - Under sampled Random forest model\n",
    "rf_mm, weight_static, prob_static = RandomForestForMulti(X_train, X_test, y_train, y_test, resampling='under')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e98a0975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1345\n",
      "Under sampling: Train: 688 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.96, 0.95, 0.97, 0.96, 0.95]\n",
      "CV:Recall   : [0.6, 0.61, 0.59, 0.61, 0.58]\n",
      "CV:F1-score : [0.74, 0.74, 0.74, 0.75, 0.72]\n",
      "\n",
      "CV:Precision Mean: 0.96\n",
      "CV:Recall Mean: 0.6\n",
      "CV:F1-score Mean: 0.74\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.1, 0.08, 0.11, 0.1, 0.09]\n",
      "CV:Recall   : [0.65, 0.53, 0.77, 0.65, 0.57]\n",
      "CV:F1-score : [0.17, 0.15, 0.2, 0.18, 0.15]\n",
      "\n",
      "CV:Precision Mean: 0.1\n",
      "CV:Recall Mean: 0.63\n",
      "CV:F1-score Mean: 0.17\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.6\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.61      0.75      1574\n",
      "           1       0.09      0.59      0.16       107\n",
      "\n",
      "    accuracy                           0.61      1681\n",
      "   macro avg       0.52      0.60      0.45      1681\n",
      "weighted avg       0.90      0.61      0.71      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Best model for labs - Under sampled Rocket model with 50 kernels\n",
    "clf_lab_mm, weight_lab, prob_lab = RocketMulti(labs_grouped,feature_labs, 50, resampling = \"Under\", filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "482ecca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution: Train: 0    6294\n",
      "1     430\n",
      "dtype: int64\n",
      "Distribution: Test : 0    1574\n",
      "1     107\n",
      "dtype: int64\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10070 Test: 1345\n",
      "Over sampling: Train: 10072 Test: 1344\n",
      "---------CV : Label 0----------------\n",
      "CV:Precision:  [0.96, 0.96, 0.95, 0.96, 0.95]\n",
      "CV:Recall   : [0.71, 0.7, 0.7, 0.72, 0.73]\n",
      "CV:F1-score : [0.81, 0.81, 0.8, 0.82, 0.83]\n",
      "\n",
      "CV:Precision Mean: 0.96\n",
      "CV:Recall Mean: 0.71\n",
      "CV:F1-score Mean: 0.81\n",
      "---------CV : Label 1----------------\n",
      "CV:Precision:  [0.12, 0.11, 0.08, 0.12, 0.11]\n",
      "CV:Recall   : [0.6, 0.56, 0.41, 0.56, 0.47]\n",
      "CV:F1-score : [0.2, 0.19, 0.14, 0.2, 0.17]\n",
      "\n",
      "CV:Precision Mean: 0.11\n",
      "CV:Recall Mean: 0.52\n",
      "CV:F1-score Mean: 0.18\n",
      "---------Accuracy CV----------------\n",
      "CV: Accuracy  0.7\n",
      "------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.73      0.83      1574\n",
      "           1       0.12      0.53      0.19       107\n",
      "\n",
      "    accuracy                           0.72      1681\n",
      "   macro avg       0.54      0.63      0.51      1681\n",
      "weighted avg       0.90      0.72      0.79      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Best model for vitals - Under sampled Rocket model\n",
    "clf_vital_mm, weight_vital, prob_vital = RocketMulti(vitals_grouped,feature_vitals, resampling = \"Over\",filtered_train_ids = train_ids_reuse, filtered_test_ids = test_ids_reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b70adc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_static 0.9435175445743688\n",
      "weight_lab 0.44878779009546316\n",
      "weight_vital 0.9317495732524895\n"
     ]
    }
   ],
   "source": [
    "print(\"weight_static\",weight_static)\n",
    "print(\"weight_lab\",weight_lab)\n",
    "print(\"weight_vital\",weight_vital) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b303a675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.08558558558558559\n",
      "Recall: 0.35514018691588783\n",
      "F1 Score: 0.13793103448275862\n",
      "Accuracy: 0.7174301011302796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.74      0.83      1574\n",
      "           1       0.09      0.36      0.14       107\n",
      "\n",
      "    accuracy                           0.72      1681\n",
      "   macro avg       0.51      0.55      0.48      1681\n",
      "weighted avg       0.89      0.72      0.79      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Weights as accuracy score\n",
    "soft_voting(rf_mm, clf_lab_mm, clf_vital_mm, weight_static, weight_lab, weight_vital,\n",
    "               prob_static, prob_lab, prob_vital, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f1539249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.08961303462321792\n",
      "Recall: 0.411214953271028\n",
      "F1 Score: 0.1471571906354515\n",
      "Accuracy: 0.6966091612135633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.72      0.82      1574\n",
      "           1       0.09      0.41      0.15       107\n",
      "\n",
      "    accuracy                           0.70      1681\n",
      "   macro avg       0.52      0.56      0.48      1681\n",
      "weighted avg       0.89      0.70      0.77      1681\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Weights as F1 score\n",
    "soft_voting(rf_mm, clf_lab_mm, clf_vital_mm, 21, 16, 19,\n",
    "               prob_static, prob_lab, prob_vital, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58ab533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
